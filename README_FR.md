# Outil de Test d'API LLM

<div align="center">

[![GitHub stars](https://img.shields.io/github/stars/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/stargazers)
[![GitHub license](https://img.shields.io/github/license/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/blob/main/LICENSE)
[![GitHub issues](https://img.shields.io/github/issues/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/issues)

**ğŸš€ Un outil complet pour tester et comparer les performances des APIs de ModÃ¨les de Langage Large**

## ğŸŒ [ğŸš€ DÃ©mo en Direct - Essayez Maintenant !](https://llmapitest.com)

**Langues :** [English](README.md) | [ä¸­æ–‡](README_CN.md) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_AR.md) | [Deutsch](README_DE.md) | [EspaÃ±ol](README_ES.md) | [FranÃ§ais](README_FR.md) | [æ—¥æœ¬èª](README_JA.md)

</div>

## ğŸ“– AperÃ§u

LLM API Test est un outil puissant basÃ© sur le web conÃ§u pour benchmarker et comparer les performances de diverses APIs de ModÃ¨les de Langage Large. Que vous Ã©valuiez diffÃ©rents fournisseurs, optimisiez vos applications IA ou meniez des recherches, cet outil fournit des mÃ©triques et des insights complets.

## âœ¨ FonctionnalitÃ©s Principales

### ğŸ”Œ Support d'API
- **OpenAI** : GPT-3.5, GPT-4 et modÃ¨les les plus rÃ©cents
- **Google Gemini** : Gemini Pro, Gemini Pro Vision
- **APIs PersonnalisÃ©es** : Tout endpoint d'API compatible OpenAI

### ğŸ“Š MÃ©triques de Performance
- **Temps de RÃ©ponse** : Mesure de la latence du premier token
- **Vitesse de Sortie** : Calcul des tokens par seconde
- **Taux de RÃ©ussite** : Suivi de la fiabilitÃ© de l'API
- **Ã‰valuation de QualitÃ©** : Outils de comparaison des rÃ©ponses

### ğŸŒ ExpÃ©rience Utilisateur
- **Interface Multilingue** : Support de 7 langues
- **Design Responsive** : Fonctionne sur desktop et mobile
- **RÃ©sultats en Temps RÃ©el** : Surveillance des performances en direct
- **Suivi d'Historique** : Enregistrements de tests persistants

### â˜ï¸ Options de DÃ©ploiement
- **DÃ©veloppement Local** : Configuration simple de serveur HTTP
- **HÃ©bergement Statique** : Compatible avec tout hÃ©bergeur statique

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Navigateur web moderne (Chrome, Firefox, Safari, Edge)
- Node.js et npm installÃ©s
- ClÃ©s API pour les services que vous souhaitez tester

### DÃ©veloppement Local

1. **Cloner le dÃ©pÃ´t**
   ```bash
   git clone https://github.com/qjr87/llm-api-test.git
   cd llm-api-test
   ```

2. **Installer les dÃ©pendances et dÃ©marrer le serveur**
   ```bash
   npm install
   npm start
   ```

   **MÃ©thodes alternatives :**
   ```bash
   # Avec Python 3
   python -m http.server 8000
   
   # Avec PHP
   php -S localhost:8000
   ```

3. **Ouvrir dans le navigateur**
   Naviguer vers `http://localhost:8000`

### ğŸ”§ Guide de Configuration

#### Configuration API
1. **SÃ©lectionner le Protocole** : Choisissez votre fournisseur d'API (OpenAI, Gemini ou PersonnalisÃ©)
2. **Entrer l'Endpoint** : URL de l'API (auto-rempli pour les fournisseurs standard)
3. **Ajouter la ClÃ© API** : Votre clÃ© d'authentification
4. **Configurer les ModÃ¨les** : SpÃ©cifiez quels modÃ¨les tester

#### ParamÃ¨tres de Test
- **Tours de Test** : Nombre d'itÃ©rations par modÃ¨le
- **Prompts** : Prompts de test personnalisÃ©s ou utiliser les dÃ©fauts
- **Concurrence** : Gestion des requÃªtes parallÃ¨les

#### Exemple de Configuration
```javascript
// Configuration OpenAI
Protocole : "openai"
URL API : "https://api.openai.com/v1/chat/completions"
ClÃ© API : "sk-..."
ModÃ¨les : "gpt-3.5-turbo,gpt-4"

// Configuration Gemini
Protocole : "gemini"
URL API : "https://generativelanguage.googleapis.com/v1beta/models"
ModÃ¨les : "gemini-pro"
```

## ğŸš€ DÃ©ploiement

### HÃ©bergement Statique

DÃ©ployez sur n'importe quel service d'hÃ©bergement statique :

- **Vercel** : `vercel --prod`
- **Netlify** : Glisser-dÃ©poser le dossier du projet
- **GitHub Pages** : Activer dans les paramÃ¨tres du dÃ©pÃ´t
- **Firebase Hosting** : `firebase deploy`

### DÃ©ploiement Docker

```dockerfile
FROM nginx:alpine
COPY . /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

```bash
docker build -t llm-api-test .
docker run -p 8080:80 llm-api-test
```

## ğŸ“ Structure du Projet

```
llm-api-test/
â”œâ”€â”€ ğŸ“„ index.html          # Interface principale de l'application
â”œâ”€â”€ ğŸ§  app.js             # Logique centrale de l'application et orchestration des tests
â”œâ”€â”€ ğŸ”Œ api-handlers.js    # ImplÃ©mentations des protocoles API
â”œâ”€â”€ ğŸ¨ styles.css         # Styles UI responsifs
â”œâ”€â”€ ğŸŒ i18n.js           # Internationalisation et support linguistique
â””â”€â”€ ğŸ“œ LICENSE           # Licence MIT
```

### Composants Principaux

- **Classe APITester** : Orchestration principale des tests et gestion de l'UI
- **Classe APIHandler** : ImplÃ©mentations d'API spÃ©cifiques au protocole
- **SystÃ¨me I18n** : Support multilingue avec chargement dynamique
- **Moteur de RÃ©sultats** : Calcul des mÃ©triques de performance en temps rÃ©el

## ğŸ› ï¸ Stack Technologique

### Frontend
- **HTML5** : Balisage sÃ©mantique et accessibilitÃ©
- **CSS3** : Styles modernes avec Flexbox/Grid
- **JavaScript Vanilla** : Aucune dÃ©pendance de framework
- **APIs Web** : Fetch, LocalStorage, Internationalisation

### Architecture
- **Design Modulaire** : SÃ©paration des prÃ©occupations
- **OrientÃ© Ã‰vÃ©nements** : Mises Ã  jour rÃ©actives de l'UI
- **AmÃ©lioration Progressive** : Fonctionne sans JavaScript
- **Mobile-First** : Principes de design responsive

### DÃ©ploiement
- **HÃ©bergement Statique** : CompatibilitÃ© universelle
- **PrÃªt pour CDN** : Distribution globale de contenu

## ğŸ“Š Explication des MÃ©triques de Performance

| MÃ©trique | Description | Bonne Plage |
|----------|-------------|-------------|
| **Temps du Premier Token** | Temps pour recevoir le premier token de rÃ©ponse | < 2 secondes |
| **Vitesse de Sortie** | Tokens gÃ©nÃ©rÃ©s par seconde | > 10 tokens/sec |
| **Taux de RÃ©ussite** | Pourcentage de requÃªtes rÃ©ussies | > 95% |
| **Temps Total** | Temps complet de gÃ©nÃ©ration de rÃ©ponse | Varie selon la longueur |

## ğŸ¤ Contribuer

Nous accueillons les contributions ! Voici comment vous pouvez aider :

### Configuration de DÃ©veloppement
1. **Forker** le dÃ©pÃ´t
2. **Cloner** votre fork localement
3. **CrÃ©er** une branche de fonctionnalitÃ©
   ```bash
   git checkout -b feature/amazing-feature
   ```
4. **Effectuer** vos modifications
5. **Tester** minutieusement
6. **Committer** avec des messages clairs
   ```bash
   git commit -m "feat: add amazing feature"
   ```
7. **Pousser** vers votre fork
8. **Soumettre** une Pull Request

### Directives de Contribution
- Suivre le style de code existant
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation
- Assurer la compatibilitÃ© cross-browser

### Domaines de Contribution
- ğŸŒ Traductions linguistiques supplÃ©mentaires
- ğŸ”Œ Support de nouveaux fournisseurs d'API
- ğŸ“Š MÃ©triques et visualisations amÃ©liorÃ©es
- ğŸ¨ AmÃ©liorations UI/UX
- ğŸ› Corrections de bugs et optimisations

## â“ FAQ

<details>
<summary><strong>Comment obtenir des clÃ©s API ?</strong></summary>

- **OpenAI** : Visitez [platform.openai.com](https://platform.openai.com/api-keys)
- **Google Gemini** : Commencez sur [ai.google.dev](https://ai.google.dev/)
- **APIs PersonnalisÃ©es** : Consultez la documentation de votre fournisseur

</details>

<details>
<summary><strong>Pourquoi mes tests Ã©chouent-ils ?</strong></summary>

- VÃ©rifiez que la clÃ© API est correcte et a suffisamment de crÃ©dits
- VÃ©rifiez si l'URL de l'endpoint API est prÃ©cise
- Assurez-vous que votre IP n'est pas bloquÃ©e par le fournisseur
- Essayez de rÃ©duire la concurrence ou les tours de test

</details>

<details>
<summary><strong>Puis-je tester des modÃ¨les personnalisÃ©s ?</strong></summary>

Oui ! Utilisez l'option de protocole "PersonnalisÃ©" et fournissez :
- Votre URL d'endpoint API
- MÃ©thode d'authentification
- Noms des modÃ¨les

</details>

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour les dÃ©tails.

## ğŸ™ Remerciements

- Merci Ã  tous les contributeurs qui aident Ã  amÃ©liorer cet outil
- InspirÃ© par le besoin de tests transparents de performance IA
- Construit avec â¤ï¸ pour la communautÃ© de dÃ©veloppement IA

---

<div align="center">

**[â­ Ã‰toiler ce dÃ©pÃ´t](https://github.com/qjr87/llm-api-test) si vous le trouvez utile !**

Fait avec â¤ï¸ par [qjr87](https://github.com/qjr87)

</div>