# Herramienta de Prueba de API LLM

<div align="center">

[![GitHub stars](https://img.shields.io/github/stars/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/stargazers)
[![GitHub license](https://img.shields.io/github/license/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/blob/main/LICENSE)
[![GitHub issues](https://img.shields.io/github/issues/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/issues)

**ğŸš€ Una herramienta integral para probar y comparar el rendimiento de APIs de Modelos de Lenguaje Grande**

## ğŸŒ [ğŸš€ Demo en Vivo - Â¡PruÃ©balo Ahora!](https://llmapitest.com)

**Idiomas:** [English](README.md) | [ä¸­æ–‡](README_CN.md) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_AR.md) | [Deutsch](README_DE.md) | [EspaÃ±ol](README_ES.md) | [FranÃ§ais](README_FR.md) | [æ—¥æœ¬èª](README_JA.md)

</div>

## ğŸ“– DescripciÃ³n General

LLM API Test es una herramienta poderosa basada en web diseÃ±ada para hacer benchmarks y comparar el rendimiento de varias APIs de Modelos de Lenguaje Grande. Ya sea que estÃ©s evaluando diferentes proveedores, optimizando tus aplicaciones de IA o realizando investigaciÃ³n, esta herramienta proporciona mÃ©tricas e insights integrales.

## âœ¨ CaracterÃ­sticas Principales

### ğŸ”Œ Soporte de API
- **OpenAI**: GPT-3.5, GPT-4 y modelos mÃ¡s recientes
- **Google Gemini**: Gemini Pro, Gemini Pro Vision
- **APIs Personalizadas**: Cualquier endpoint de API compatible con OpenAI

### ğŸ“Š MÃ©tricas de Rendimiento
- **Tiempo de Respuesta**: MediciÃ³n de latencia del primer token
- **Velocidad de Salida**: CÃ¡lculo de tokens por segundo
- **Tasa de Ã‰xito**: Seguimiento de confiabilidad de API
- **EvaluaciÃ³n de Calidad**: Herramientas de comparaciÃ³n de respuestas

### ğŸŒ Experiencia de Usuario
- **Interfaz Multiidioma**: Soporte para 7 idiomas
- **DiseÃ±o Responsivo**: Funciona en escritorio y mÃ³vil
- **Resultados en Tiempo Real**: Monitoreo de rendimiento en vivo
- **Seguimiento de Historial**: Registros de prueba persistentes

### â˜ï¸ Opciones de Despliegue
- **Desarrollo Local**: ConfiguraciÃ³n simple de servidor HTTP
- **Hosting EstÃ¡tico**: Compatible con cualquier host estÃ¡tico

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos
- Navegador web moderno (Chrome, Firefox, Safari, Edge)
- Node.js y npm instalados
- Claves API para los servicios que deseas probar

### Desarrollo Local

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/qjr87/llm-api-test.git
   cd llm-api-test
   ```

2. **Instalar dependencias e iniciar el servidor**
   ```bash
   npm install
   npm start
   ```

   **MÃ©todos alternativos:**
   ```bash
   # Usando Python 3
   python -m http.server 8000
   
   # Usando PHP
   php -S localhost:8000
   ```

3. **Abrir en el navegador**
   Navegar a `http://localhost:8000`

### ğŸ”§ GuÃ­a de ConfiguraciÃ³n

#### ConfiguraciÃ³n de API
1. **Seleccionar Protocolo**: Elige tu proveedor de API (OpenAI, Gemini o Personalizado)
2. **Ingresar Endpoint**: URL de API (auto-completado para proveedores estÃ¡ndar)
3. **Agregar Clave API**: Tu clave de autenticaciÃ³n
4. **Configurar Modelos**: Especifica quÃ© modelos probar

#### ParÃ¡metros de Prueba
- **Rondas de Prueba**: NÃºmero de iteraciones por modelo
- **Prompts**: Prompts de prueba personalizados o usar predeterminados
- **Concurrencia**: Manejo de solicitudes paralelas

#### Ejemplo de ConfiguraciÃ³n
```javascript
// ConfiguraciÃ³n OpenAI
Protocolo: "openai"
URL API: "https://api.openai.com/v1/chat/completions"
Clave API: "sk-..."
Modelos: "gpt-3.5-turbo,gpt-4"

// ConfiguraciÃ³n Gemini
Protocolo: "gemini"
URL API: "https://generativelanguage.googleapis.com/v1beta/models"
Modelos: "gemini-pro"
```

## ğŸš€ Despliegue

### Hosting EstÃ¡tico

Despliega en cualquier servicio de hosting estÃ¡tico:

- **Vercel**: `vercel --prod`
- **Netlify**: Arrastra y suelta la carpeta del proyecto
- **GitHub Pages**: Habilita en la configuraciÃ³n del repositorio
- **Firebase Hosting**: `firebase deploy`

### Despliegue con Docker

```dockerfile
FROM nginx:alpine
COPY . /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

```bash
docker build -t llm-api-test .
docker run -p 8080:80 llm-api-test
```

## ğŸ“ Estructura del Proyecto

```
llm-api-test/
â”œâ”€â”€ ğŸ“„ index.html          # Interfaz principal de la aplicaciÃ³n
â”œâ”€â”€ ğŸ§  app.js             # LÃ³gica central de la aplicaciÃ³n y orquestaciÃ³n de pruebas
â”œâ”€â”€ ğŸ”Œ api-handlers.js    # Implementaciones de protocolos API
â”œâ”€â”€ ğŸ¨ styles.css         # Estilos de UI responsivos
â”œâ”€â”€ ğŸŒ i18n.js           # InternacionalizaciÃ³n y soporte de idiomas
â””â”€â”€ ğŸ“œ LICENSE           # Licencia MIT
```

### Componentes Principales

- **Clase APITester**: OrquestaciÃ³n principal de pruebas y gestiÃ³n de UI
- **Clase APIHandler**: Implementaciones de API especÃ­ficas por protocolo
- **Sistema I18n**: Soporte multiidioma con carga dinÃ¡mica
- **Motor de Resultados**: CÃ¡lculo de mÃ©tricas de rendimiento en tiempo real

## ğŸ› ï¸ Stack TecnolÃ³gico

### Frontend
- **HTML5**: Marcado semÃ¡ntico y accesibilidad
- **CSS3**: Estilos modernos con Flexbox/Grid
- **JavaScript Vanilla**: Sin dependencias de frameworks
- **APIs Web**: Fetch, LocalStorage, InternacionalizaciÃ³n

### Arquitectura
- **DiseÃ±o Modular**: SeparaciÃ³n de responsabilidades
- **Orientado a Eventos**: Actualizaciones reactivas de UI
- **Mejora Progresiva**: Funciona sin JavaScript
- **Mobile-First**: Principios de diseÃ±o responsivo

### Despliegue
- **Hosting EstÃ¡tico**: Compatibilidad universal
- **Listo para CDN**: DistribuciÃ³n global de contenido

## ğŸ“Š ExplicaciÃ³n de MÃ©tricas de Rendimiento

| MÃ©trica | DescripciÃ³n | Rango Bueno |
|---------|-------------|-------------|
| **Tiempo del Primer Token** | Tiempo para recibir el primer token de respuesta | < 2 segundos |
| **Velocidad de Salida** | Tokens generados por segundo | > 10 tokens/seg |
| **Tasa de Ã‰xito** | Porcentaje de solicitudes exitosas | > 95% |
| **Tiempo Total** | Tiempo completo de generaciÃ³n de respuesta | VarÃ­a segÃºn longitud |

## ğŸ¤ Contribuir

Â¡Damos la bienvenida a las contribuciones! AsÃ­ es como puedes ayudar:

### ConfiguraciÃ³n de Desarrollo
1. **Hacer Fork** del repositorio
2. **Clonar** tu fork localmente
3. **Crear** una rama de caracterÃ­stica
   ```bash
   git checkout -b feature/amazing-feature
   ```
4. **Realizar** tus cambios
5. **Probar** exhaustivamente
6. **Hacer Commit** con mensajes claros
   ```bash
   git commit -m "feat: add amazing feature"
   ```
7. **Hacer Push** a tu fork
8. **Enviar** un Pull Request

### Pautas de ContribuciÃ³n
- Seguir el estilo de cÃ³digo existente
- Agregar pruebas para nuevas caracterÃ­sticas
- Actualizar documentaciÃ³n
- Asegurar compatibilidad entre navegadores

### Ãreas para ContribuciÃ³n
- ğŸŒ Traducciones de idiomas adicionales
- ğŸ”Œ Soporte para nuevos proveedores de API
- ğŸ“Š MÃ©tricas y visualizaciones mejoradas
- ğŸ¨ Mejoras de UI/UX
- ğŸ› CorrecciÃ³n de errores y optimizaciones

## â“ Preguntas Frecuentes

<details>
<summary><strong>Â¿CÃ³mo obtengo claves API?</strong></summary>

- **OpenAI**: Visita [platform.openai.com](https://platform.openai.com/api-keys)
- **Google Gemini**: Comienza en [ai.google.dev](https://ai.google.dev/)
- **APIs Personalizadas**: Consulta la documentaciÃ³n de tu proveedor

</details>

<details>
<summary><strong>Â¿Por quÃ© fallan mis pruebas?</strong></summary>

- Verifica que la clave API sea correcta y tenga crÃ©ditos suficientes
- Comprueba si la URL del endpoint API es precisa
- AsegÃºrate de que tu IP no estÃ© bloqueada por el proveedor
- Intenta reducir la concurrencia o las rondas de prueba

</details>

<details>
<summary><strong>Â¿Puedo probar modelos personalizados?</strong></summary>

Â¡SÃ­! Usa la opciÃ³n de protocolo "Personalizado" y proporciona:
- Tu URL de endpoint API
- MÃ©todo de autenticaciÃ³n
- Nombres de modelos

</details>

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - consulta el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- Gracias a todos los contribuyentes que ayudan a mejorar esta herramienta
- Inspirado por la necesidad de pruebas transparentes de rendimiento de IA
- Construido con â¤ï¸ para la comunidad de desarrollo de IA

---

<div align="center">

**[â­ Dale estrella a este repo](https://github.com/qjr87/llm-api-test) si te resulta Ãºtil!**

Hecho con â¤ï¸ por [qjr87](https://github.com/qjr87)

</div>