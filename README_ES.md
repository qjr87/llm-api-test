# Herramienta de Prueba de API LLM

**Read this in other languages**: [English](README.md) | [ä¸­æ–‡](README_CN.md) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_AR.md) | [Deutsch](README_DE.md) | [FranÃ§ais](README_FR.md) | [æ—¥æœ¬èª](README_JA.md)

Una herramienta para probar y comparar el rendimiento de diferentes APIs de Modelos de Lenguaje Grande.

## CaracterÃ­sticas

- ğŸš€ **Soporte Multi-API**: Compatible con OpenAI, Google Gemini y otras APIs LLM principales
- âš¡ **Pruebas de Rendimiento**: Mide el tiempo de respuesta del primer token, velocidad de salida y tasa de Ã©xito
- ğŸ“Š **VisualizaciÃ³n de Datos**: VisualizaciÃ³n en tiempo real de resultados de pruebas y estadÃ­sticas
- ğŸŒ **Soporte Multiidioma**: Disponible en inglÃ©s, chino, francÃ©s, japonÃ©s, alemÃ¡n, espaÃ±ol y Ã¡rabe
- ğŸ“± **DiseÃ±o Responsivo**: Se adapta a dispositivos de escritorio y mÃ³viles
- ğŸ’¾ **Registros de Historial**: Guardado automÃ¡tico del historial de pruebas con opciones de exportaciÃ³n de datos
- â˜ï¸ **Cloudflare Workers**: Soporta despliegue en plataformas de computaciÃ³n en el borde

## Inicio RÃ¡pido

### ConfiguraciÃ³n Local

1. Clonar el repositorio
```bash
git clone https://github.com/your-username/llm-api-test.git
cd llm-api-test
```

2. Iniciar un servidor local
```bash
python -m http.server 8000
```

3. Abrir el navegador y navegar a `http://localhost:8000`

### ConfiguraciÃ³n de API

1. Seleccionar el proveedor de API que deseas probar en el Ã¡rea de configuraciÃ³n
2. Introducir la clave API y endpoint correspondientes
3. Establecer parÃ¡metros de prueba (rondas, concurrencia, etc.)
4. Hacer clic en el botÃ³n "Iniciar Prueba"

## APIs Soportadas

- **OpenAI**: Modelos de la serie GPT-3.5, GPT-4
- **Google Gemini**: Gemini Pro, Gemini Pro Vision
- **APIs Personalizadas**: Soporte para otras APIs compatibles con el formato OpenAI

## Despliegue

### Despliegue en Cloudflare Workers

1. Instalar Wrangler CLI
```bash
npm install -g wrangler
```

2. Iniciar sesiÃ³n en Cloudflare
```bash
wrangler login
```

3. Construir y desplegar
```bash
node build-worker.js
wrangler deploy
```

Para instrucciones detalladas de despliegue, consulte [DEPLOYMENT.md](DEPLOYMENT.md)

## Estructura del Proyecto

```
llm-api-test/
â”œâ”€â”€ index.html          # PÃ¡gina principal
â”œâ”€â”€ app.js             # LÃ³gica principal de la aplicaciÃ³n
â”œâ”€â”€ api-handlers.js    # Manejadores de API
â”œâ”€â”€ styles.css         # Hoja de estilos
â”œâ”€â”€ i18n.js           # ConfiguraciÃ³n de internacionalizaciÃ³n
â”œâ”€â”€ worker.js         # Script de Cloudflare Workers
â”œâ”€â”€ build-worker.js   # Script de construcciÃ³n de Workers
â””â”€â”€ wrangler.toml     # ConfiguraciÃ³n de Cloudflare
```

## Stack TecnolÃ³gico

- **Frontend**: HTML/CSS/JavaScript nativo
- **Despliegue**: Cloudflare Workers
- **APIs**: Soporte para mÃºltiples APIs LLM
- **InternacionalizaciÃ³n**: Soporte multiidioma

## Contribuir

Â¡Las contribuciones son bienvenidas! No dudes en enviar Issues y Pull Requests.

1. Hacer fork del proyecto
2. Crear tu rama de caracterÃ­sticas (`git checkout -b feature/AmazingFeature`)
3. Hacer commit de tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Hacer push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## Licencia

Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles