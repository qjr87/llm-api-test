# LLM API Test-Tool

<div align="center">

[![GitHub stars](https://img.shields.io/github/stars/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/stargazers)
[![GitHub license](https://img.shields.io/github/license/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/blob/main/LICENSE)
[![GitHub issues](https://img.shields.io/github/issues/qjr87/llm-api-test?style=flat-square)](https://github.com/qjr87/llm-api-test/issues)

**ğŸš€ Ein umfassendes Tool zum Testen und Vergleichen der Leistung von Large Language Model APIs**

## ğŸŒ [ğŸš€ Live-Demo - Jetzt ausprobieren!](https://llmapitest.com)

**Sprachen:** [English](README.md) | [ä¸­æ–‡](README_CN.md) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_AR.md) | [Deutsch](README_DE.md) | [EspaÃ±ol](README_ES.md) | [FranÃ§ais](README_FR.md) | [æ—¥æœ¬èª](README_JA.md)

</div>

## ğŸ“– Ãœberblick

LLM API Test ist ein leistungsstarkes, webbasiertes Tool, das entwickelt wurde, um die Leistung verschiedener Large Language Model APIs zu benchmarken und zu vergleichen. Ob Sie verschiedene Anbieter bewerten, Ihre KI-Anwendungen optimieren oder Forschung betreiben - dieses Tool bietet umfassende Metriken und Einblicke.

## âœ¨ Hauptfunktionen

### ğŸ”Œ API-UnterstÃ¼tzung
- **OpenAI**: GPT-3.5, GPT-4 und neueste Modelle
- **Google Gemini**: Gemini Pro, Gemini Pro Vision
- **Benutzerdefinierte APIs**: Jeder OpenAI-kompatible API-Endpunkt

### ğŸ“Š Leistungsmetriken
- **Antwortzeit**: Messung der ersten Token-Latenz
- **Ausgabegeschwindigkeit**: Berechnung der Token pro Sekunde
- **Erfolgsrate**: Verfolgung der API-ZuverlÃ¤ssigkeit
- **QualitÃ¤tsbewertung**: Tools zum Vergleich von Antworten

### ğŸŒ Benutzererfahrung
- **Mehrsprachige OberflÃ¤che**: UnterstÃ¼tzung fÃ¼r 7 Sprachen
- **Responsives Design**: Funktioniert auf Desktop und MobilgerÃ¤ten
- **Echtzeitresultate**: Live-LeistungsÃ¼berwachung
- **Verlaufsverfolgung**: Persistente Testaufzeichnungen

### â˜ï¸ Bereitstellungsoptionen
- **Lokale Entwicklung**: Einfache HTTP-Server-Einrichtung
- **Statisches Hosting**: Kompatibel mit jedem statischen Host

## ğŸš€ Schnellstart

### Voraussetzungen
- Moderner Webbrowser (Chrome, Firefox, Safari, Edge)
- Node.js und npm installiert
- API-SchlÃ¼ssel fÃ¼r die Dienste, die Sie testen mÃ¶chten

### Lokale Entwicklung

1. **Repository klonen**
   ```bash
   git clone https://github.com/qjr87/llm-api-test.git
   cd llm-api-test
   ```

2. **AbhÃ¤ngigkeiten installieren und Server starten**
   ```bash
   npm install
   npm start
   ```

   **Alternative Methoden:**
   ```bash
   # Mit Python 3
   python -m http.server 8000
   
   # Mit PHP
   php -S localhost:8000
   ```

3. **Im Browser Ã¶ffnen**
   Navigieren Sie zu `http://localhost:8000`

### ğŸ”§ Konfigurationsleitfaden

#### API-Einrichtung
1. **Protokoll auswÃ¤hlen**: WÃ¤hlen Sie Ihren API-Anbieter (OpenAI, Gemini oder Benutzerdefiniert)
2. **Endpunkt eingeben**: API-URL (automatisch ausgefÃ¼llt fÃ¼r Standardanbieter)
3. **API-SchlÃ¼ssel hinzufÃ¼gen**: Ihr AuthentifizierungsschlÃ¼ssel
4. **Modelle konfigurieren**: Geben Sie an, welche Modelle getestet werden sollen

#### Testparameter
- **Testrunden**: Anzahl der Iterationen pro Modell
- **Prompts**: Benutzerdefinierte Testprompts oder Standardwerte verwenden
- **ParallelitÃ¤t**: Parallele Anfrageverarbeitung

#### Beispielkonfiguration
```javascript
// OpenAI-Konfiguration
Protokoll: "openai"
API-URL: "https://api.openai.com/v1/chat/completions"
API-SchlÃ¼ssel: "sk-..."
Modelle: "gpt-3.5-turbo,gpt-4"

// Gemini-Konfiguration
Protokoll: "gemini"
API-URL: "https://generativelanguage.googleapis.com/v1beta/models"
Modelle: "gemini-pro"
```

## ğŸš€ Bereitstellung

### Statisches Hosting

Bereitstellung auf jedem statischen Hosting-Dienst:

- **Vercel**: `vercel --prod`
- **Netlify**: Projektordner per Drag & Drop
- **GitHub Pages**: In Repository-Einstellungen aktivieren
- **Firebase Hosting**: `firebase deploy`

### Docker-Bereitstellung

```dockerfile
FROM nginx:alpine
COPY . /usr/share/nginx/html
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

```bash
docker build -t llm-api-test .
docker run -p 8080:80 llm-api-test
```

## ğŸ“ Projektstruktur

```
llm-api-test/
â”œâ”€â”€ ğŸ“„ index.html          # Hauptanwendungsschnittstelle
â”œâ”€â”€ ğŸ§  app.js             # Kernanwendungslogik und Testorchestration
â”œâ”€â”€ ğŸ”Œ api-handlers.js    # API-Protokollimplementierungen
â”œâ”€â”€ ğŸ¨ styles.css         # Responsives UI-Styling
â”œâ”€â”€ ğŸŒ i18n.js           # Internationalisierung und SprachunterstÃ¼tzung
â””â”€â”€ ğŸ“œ LICENSE           # MIT-Lizenz
```

### Kernkomponenten

- **APITester-Klasse**: Haupttestorchestration und UI-Verwaltung
- **APIHandler-Klasse**: Protokollspezifische API-Implementierungen
- **I18n-System**: Mehrsprachige UnterstÃ¼tzung mit dynamischem Laden
- **Ergebnis-Engine**: Echtzeitberechnung von Leistungsmetriken

## ğŸ› ï¸ Tech-Stack

### Frontend
- **HTML5**: Semantisches Markup und Barrierefreiheit
- **CSS3**: Modernes Styling mit Flexbox/Grid
- **Vanilla JavaScript**: Keine Framework-AbhÃ¤ngigkeiten
- **Web-APIs**: Fetch, LocalStorage, Internationalisierung

### Architektur
- **Modulares Design**: Trennung der Belange
- **Ereignisgesteuert**: Reaktive UI-Updates
- **Progressive Verbesserung**: Funktioniert ohne JavaScript
- **Mobile-First**: Responsive Design-Prinzipien

### Bereitstellung
- **Statisches Hosting**: Universelle KompatibilitÃ¤t
- **CDN-bereit**: Globale Inhaltsverteilung

## ğŸ“Š ErklÃ¤rung der Leistungsmetriken

| Metrik | Beschreibung | Guter Bereich |
|--------|--------------|---------------|
| **Erste Token-Zeit** | Zeit bis zum Empfang des ersten Antwort-Tokens | < 2 Sekunden |
| **Ausgabegeschwindigkeit** | Generierte Token pro Sekunde | > 10 Token/Sek |
| **Erfolgsrate** | Prozentsatz erfolgreicher Anfragen | > 95% |
| **Gesamtzeit** | VollstÃ¤ndige Antwortgenerierungszeit | Variiert je nach LÃ¤nge |

## ğŸ¤ Mitwirken

Wir begrÃ¼ÃŸen BeitrÃ¤ge! So kÃ¶nnen Sie helfen:

### Entwicklungssetup
1. Repository **forken**
2. Ihren Fork lokal **klonen**
3. Feature-Branch **erstellen**
   ```bash
   git checkout -b feature/amazing-feature
   ```
4. Ã„nderungen **vornehmen**
5. **GrÃ¼ndlich testen**
6. Mit klaren Nachrichten **committen**
   ```bash
   git commit -m "feat: add amazing feature"
   ```
7. Zu Ihrem Fork **pushen**
8. Pull Request **einreichen**

### Beitragsrichtlinien
- Bestehenden Code-Stil befolgen
- Tests fÃ¼r neue Features hinzufÃ¼gen
- Dokumentation aktualisieren
- Cross-Browser-KompatibilitÃ¤t sicherstellen

### Bereiche fÃ¼r BeitrÃ¤ge
- ğŸŒ ZusÃ¤tzliche SprachÃ¼bersetzungen
- ğŸ”Œ Neue API-Anbieter-UnterstÃ¼tzung
- ğŸ“Š Erweiterte Metriken und Visualisierungen
- ğŸ¨ UI/UX-Verbesserungen
- ğŸ› Fehlerbehebungen und Optimierungen

## â“ HÃ¤ufig gestellte Fragen

<details>
<summary><strong>Wie erhalte ich API-SchlÃ¼ssel?</strong></summary>

- **OpenAI**: Besuchen Sie [platform.openai.com](https://platform.openai.com/api-keys)
- **Google Gemini**: Beginnen Sie bei [ai.google.dev](https://ai.google.dev/)
- **Benutzerdefinierte APIs**: ÃœberprÃ¼fen Sie die Dokumentation Ihres Anbieters

</details>

<details>
<summary><strong>Warum schlagen meine Tests fehl?</strong></summary>

- ÃœberprÃ¼fen Sie, ob der API-SchlÃ¼ssel korrekt ist und ausreichend Guthaben hat
- PrÃ¼fen Sie, ob die API-Endpunkt-URL korrekt ist
- Stellen Sie sicher, dass Ihre IP nicht vom Anbieter blockiert wird
- Versuchen Sie, ParallelitÃ¤t oder Testrunden zu reduzieren

</details>

<details>
<summary><strong>Kann ich benutzerdefinierte Modelle testen?</strong></summary>

Ja! Verwenden Sie die "Benutzerdefiniert"-Protokolloption und geben Sie an:
- Ihre API-Endpunkt-URL
- Authentifizierungsmethode
- Modellnamen

</details>

## ğŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die [LICENSE](LICENSE)-Datei fÃ¼r Details.

## ğŸ™ Danksagungen

- Dank an alle Mitwirkenden, die helfen, dieses Tool zu verbessern
- Inspiriert von der Notwendigkeit transparenter KI-Leistungstests
- Mit â¤ï¸ fÃ¼r die KI-Entwicklungsgemeinschaft erstellt

---

<div align="center">

**[â­ Dieses Repo bewerten](https://github.com/qjr87/llm-api-test), wenn Sie es hilfreich finden!**

Mit â¤ï¸ von [qjr87](https://github.com/qjr87) erstellt

</div>