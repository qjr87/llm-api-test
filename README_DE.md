# LLM API Test Tool

**Read this in other languages**: [English](README.md) | [ä¸­æ–‡](README_CN.md) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](README_AR.md) | [EspaÃ±ol](README_ES.md) | [FranÃ§ais](README_FR.md) | [æ—¥æœ¬èª](README_JA.md)

Ein Tool zum Testen und Vergleichen der Leistung verschiedener Large Language Model APIs.

## Funktionen

- ğŸš€ **Multi-API-UnterstÃ¼tzung**: Kompatibel mit OpenAI, Google Gemini und anderen wichtigen LLM-APIs
- âš¡ **Leistungstests**: Misst die Antwortzeit des ersten Tokens, Ausgabegeschwindigkeit und Erfolgsrate
- ğŸ“Š **Datenvisualisierung**: Echtzeitanzeige von Testergebnissen und Statistiken
- ğŸŒ **Mehrsprachige UnterstÃ¼tzung**: VerfÃ¼gbar in Englisch, Chinesisch, FranzÃ¶sisch, Japanisch, Deutsch, Spanisch und Arabisch
- ğŸ“± **Responsives Design**: Passt sich an Desktop- und MobilgerÃ¤te an
- ğŸ’¾ **VerlaufsdatensÃ¤tze**: Automatisches Speichern der Testhistorie mit Datenexportoptionen
- â˜ï¸ **Cloudflare Workers**: UnterstÃ¼tzt die Bereitstellung auf Edge-Computing-Plattformen

## Schnellstart

### Lokale Einrichtung

1. Repository klonen
```bash
git clone https://github.com/your-username/llm-api-test.git
cd llm-api-test
```

2. Lokalen Server starten
```bash
python -m http.server 8000
```

3. Browser Ã¶ffnen und zu `http://localhost:8000` navigieren

### API-Konfiguration

1. WÃ¤hlen Sie den API-Anbieter aus, den Sie im Konfigurationsbereich testen mÃ¶chten
2. Geben Sie den entsprechenden API-SchlÃ¼ssel und Endpunkt ein
3. Testparameter festlegen (Runden, ParallelitÃ¤t usw.)
4. Klicken Sie auf die SchaltflÃ¤che "Test starten"

## UnterstÃ¼tzte APIs

- **OpenAI**: GPT-3.5, GPT-4 Serie Modelle
- **Google Gemini**: Gemini Pro, Gemini Pro Vision
- **Benutzerdefinierte APIs**: UnterstÃ¼tzung fÃ¼r andere APIs, die mit dem OpenAI-Format kompatibel sind

## Bereitstellung

### Cloudflare Workers Bereitstellung

1. Wrangler CLI installieren
```bash
npm install -g wrangler
```

2. Bei Cloudflare anmelden
```bash
wrangler login
```

3. Erstellen und bereitstellen
```bash
node build-worker.js
wrangler deploy
```

Detaillierte Bereitstellungsanweisungen finden Sie in [DEPLOYMENT.md](DEPLOYMENT.md)

## Projektstruktur

```
llm-api-test/
â”œâ”€â”€ index.html          # Hauptseite
â”œâ”€â”€ app.js             # Hauptanwendungslogik
â”œâ”€â”€ api-handlers.js    # API-Handler
â”œâ”€â”€ styles.css         # Stylesheet
â”œâ”€â”€ i18n.js           # Internationalisierungskonfiguration
â”œâ”€â”€ worker.js         # Cloudflare Workers Skript
â”œâ”€â”€ build-worker.js   # Workers Build-Skript
â””â”€â”€ wrangler.toml     # Cloudflare-Konfiguration
```

## Tech Stack

- **Frontend**: Natives HTML/CSS/JavaScript
- **Bereitstellung**: Cloudflare Workers
- **APIs**: UnterstÃ¼tzung fÃ¼r mehrere LLM-APIs
- **Internationalisierung**: Mehrsprachige UnterstÃ¼tzung

## Mitwirken

BeitrÃ¤ge sind willkommen! ZÃ¶gern Sie nicht, Issues und Pull Requests einzureichen.

1. Projekt forken
2. Feature-Branch erstellen (`git checkout -b feature/AmazingFeature`)
3. Ã„nderungen committen (`git commit -m 'Add some AmazingFeature'`)
4. Zum Branch pushen (`git push origin feature/AmazingFeature`)
5. Pull Request Ã¶ffnen

## Lizenz

MIT-Lizenz - siehe [LICENSE](LICENSE) Datei fÃ¼r Details